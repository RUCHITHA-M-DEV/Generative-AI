{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Answers \u2013 Unit 1 Model Benchmark Challenge**\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "-ZIh8t2csUiV"
   },
   "id": "-ZIh8t2csUiV"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Key Concepts Understood\n",
    "Through this assignment, the architectural differences between encoder-only models (BERT, RoBERTa) and encoder\u2013decoder models (BART) were clearly understood. The experiments showed that a model\u2019s training objective and architecture strongly influence its performance on different NLP tasks. It also highlighted why using a model outside its intended design leads to poor or unstable results.\n"
   ],
   "metadata": {
    "id": "E3dTPMyVsgUg"
   },
   "id": "E3dTPMyVsgUg"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3641bc5-d46a-45af-9327-723279107979",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 983,
     "referenced_widgets": [
      "46fe0671b98543aeaf2b0d59a02bac87",
      "a49a7c4634e84e2f90664268bd3be3b2",
      "b546bade99ad4e3797d9a95a4e2c94d1",
      "07b1fd8b2221412581bcb29f27e9e5c3",
      "b235dceb4e45460f80c8a4db4a067a62",
      "58b04396ce754cdd96b3857439238432",
      "7407464972c34c2e96018502ef4803b1",
      "085b3661985b46158b4ab27f8c24c269",
      "b99c9032eae04da3a6566d0e7788bb45",
      "602666bd89fe4347973e399d961ec7e0",
      "c853cdce8cab4bfd83de370facf951ad",
      "745a3cfb80ef449eb4586391f22f2c5b",
      "028f8f2ac88c45d2b0a6ac72d9557c77",
      "4b591e7c4342421896e156bfddf6d4ae",
      "1bf0ae3071dd431a969b1b6437b70afe",
      "d810be31ba214840a4cee62723524286",
      "ae3ce5f5d8f84288a0e20194948f3aae",
      "5a6622ff1b5447c5b3dec9624a00a363",
      "054c5b456204455d9fa77d80e720b04c",
      "a298f8eff53f49a293991a871f8a8002",
      "d69b4e22b9114e06a43f826197567ec3",
      "0a7ea0dc5de843f0bd77f6bc12256270",
      "5bf7e62cfa894b7dab56b2fe039ac9ef",
      "a54f7dd82e7d41caa990413b13dc8775",
      "1a8804f5660347c8a4c135c62e8c7a4c",
      "eb6cdadea0594177979ade8bce829116",
      "a93d4f3987da40ee9c1bf71a1e12a1f3",
      "84b7d084cf8545a3a1038a5101ab48d3",
      "7a39319497f548058af2c6e5324527e2",
      "8c178d394cff4440843024f78945795d",
      "057e2c2bb20945e88a61c59c8fb039fd",
      "42515b1db01f44c6a29be628e0c1f2dc",
      "88797c085fe648fb9a24c3d3c922e24c",
      "95e2a56a4cbd440b9074c3658fba139b",
      "45465feaf6ca4e459b9cafa336b921d9",
      "0718fda4245d4022b9e9e672544aea09",
      "4cefcd107da14409a09fbc2a824195d5",
      "6a8a4120cd174e2c93d2dc48b04bf260",
      "b717b843c75441d4ba8bcfc146dab67a",
      "5b7c8ff169b34bc49c9d84c5d97dcdb3",
      "339e405ce0b84558a998bb850cb5f334",
      "900ca683c7be41c4aa7c1f9103146ee9",
      "35d9f455efa24c9db5cda369f3c6f531",
      "17675327e54b4ccfb256da9b0c2a9a3a",
      "e1f2fc2b9674471f95ae7f7f0baba389",
      "f459f5fcfcf141de8d96bab33990f807",
      "a44f70c7ef6c4ce9b3bc22d02a63f4ce",
      "410aad410fb343ce93cdbfa5bebcaf4a",
      "baacab2dd54a4885816770cb25693e2b",
      "58ada0f689ac452baa2d4b31e511ecb1",
      "6eaea8030d4348b28804422e0aa95e99",
      "2932d4adb7fb4334ae0391eba93e5324",
      "27b9a5c5704140ae8d4ed9fe69dba5e0",
      "24ef2c385c324a9d9b7c15f532a3b892",
      "c09b7709267a420fac40985d9f2693bd",
      "f040826eb2d54382af5e2bd936589e4c",
      "fe9d8ac2677c405e9c91b9a8e86e374d",
      "7510d40a824c4117bffca823deb99d05",
      "3f19b913217b4a9ca228f746e958be31",
      "e5e82527aea64c0295ebfb170aa6ae60",
      "b682e5ad580745dfbac2314db653a7b7",
      "df0b37473a864fa492a15ae9c4a82157",
      "bc815e919efd4620a6720cce573ced12",
      "075b508fb7164459837f3507ee423c6a",
      "769fda7fe12445ab9f632c67be6f84b1",
      "40ca42af648e4c3f81bfddff1ba94aaa",
      "92d3c0c9d87c41df82568309193031d8",
      "1c4a0be49d584a3b87273647a0c8879a",
      "e6251546ac254f8ab6fc93efc9316fd7",
      "d12252205f164f819ab8732012d0516c",
      "a58492e221fb4138b3faa567277d04f5",
      "a7d79940fe764ce8a45b9c95fd0b68a3",
      "6d6d95486acb491faefa056ac47a74f0",
      "c8be28f37d8141a695d661bf5ea73d51",
      "bf6c0475cf5443dd90a5b81b26e26f2d",
      "da49bfdba2b54b8da62dd41773476093",
      "f22f7895657543c4a990bc4d757eb776",
      "21082fb0a181488bb552e25434da4f2d",
      "d978553ae45144518e58ea529478e1ea",
      "aaae0f7f3c9d4c96bcdd3ec266d0b423",
      "df9b5602598943afbaafb1ef2e5811d0",
      "b6bbc9ba844545b7a74bc94cee94f0cb",
      "15d630e504a8470b9da04ef6cff7aed3",
      "7ddbb0d8c06642d0a840399be288af68",
      "b9d1b214fd1443818504b31e04c3ef7d",
      "c1d33aac0e9b4ed1a966443bc8ba9511",
      "67e05b1c44404f8c9d6e8e38784b12de",
      "0807ed436e964605aa3290bda44e21ef",
      "2d2c951610d64c518ef81e0a327114b2",
      "dda7c95ae9cc48eb9ab7ecd3ed5926e0",
      "29bc9e6044da4728b16e848da7536f38",
      "782a595b0a4c4f5eb08eeb21f7a99ef1",
      "19e494ac76e544d59f57c7c0bc9dc07a",
      "5fcdd17fc973432687f7fa79b196d84a",
      "78d9323f10cb412c9659897c8bdc4c39",
      "ab22fa6da3a040bda9836935f14fae08",
      "848fb279916148af803b3d5259655587",
      "830fcef57a6d4816be000687d57b2a0f",
      "fd6e6a7a141941fc8659c91c5ccc2375",
      "8b48fe96ca14405f89767b3f756ceed1",
      "8633d3ea69c640c0b0dee20c888a982f",
      "d9a41a10b06440e58096a2e5005c6248",
      "d23d17073a1649e09f4de66608d50cb5",
      "14f658637baf48ec88301db77c2beec5",
      "74630e7bfe974f71b1d9eb82d0cbb377",
      "27826dc9a98d4a9685aae1aa262a9c9d",
      "261bdfc642e14468b2a1231a08dda24f",
      "2371944d309c4681bdf6fb714fe2bfab",
      "a93d694212da4fd1afd19fc1c797256f",
      "1a46a698ec07415cb53311890ddcea9e",
      "5c9c7cf6f1a14b5f8f0e125bb9986af6",
      "3b82fe99bc5344a39891a478edc047e4",
      "8b562e06040946409854574b3a90f0dd",
      "85cd5663e7e348909fc8409cc329e673",
      "280ff98a7f9c4fb199db3b23469514c7",
      "27872e747e7946d0963800b1c74bf6e4",
      "3c9eded275d046ee9e14b8828be2227e",
      "1a908c423b8446ddb5b7e29a8562a00d",
      "582ddca750f14a1f9b3f8822fa1a4e2a",
      "4c33a585af9844d29121ddc6c675f61c",
      "f4ed4f3e6d5b4385adf240921e649608",
      "38c7cea6efeb4e41aba050189daec4af",
      "a0f4c40163a34691b04223c92a0696df",
      "b53d3a1b65a14197979bec82e68a6915",
      "3969d90ae09d4f07b40c78aa7ee7b70f",
      "50301d50daf341d3b463fe771b256876",
      "3c874700fb8c4015957b17d46af79c5e",
      "14190f41ff364a78b0e7a82aeb08beb2",
      "e5b2ea62141d4bf88933dc869d0a76e6",
      "a7ebcac8491e4e69ae1ed587e8381be3",
      "a77a5ecfb4ac4fe3862d1cc648ca2e55",
      "874e487552ff41da89141bf775e2bd97",
      "56f498af01a748dcaee73ad573415b7a",
      "44460edd16df44a69ddcfcae79c9efff",
      "4817d03dc5c8499b8e177bd92fb0d21d",
      "a5ea9560b80248239490ec4219b9041c",
      "5b79d1ead8e64ccb87cc553548da0deb",
      "ead399f643db490cb9020dda06db405c",
      "25bd208108bf40f5b99884c7c48e05bf",
      "71f66fc5c70d4fe2811bc537767de5e0",
      "b1d796bc64ae43aeb84f54bd242f3d54",
      "adfea600689445afaea7f8187f0b935e",
      "ca622daef79f47fa80e291cc339fdeed",
      "08093ec6a7d44ea0a48ac54506a97482",
      "93d4085f2d534ab8baee27ef90f5962a",
      "8048b6d6395a409d9aa671f42573ccaa",
      "42b6366798c140b58d6e7de6ce0e76ff",
      "54c23d67f59e457fb3e0736fb834bc65",
      "72eb605aa9ce419fb06208495a152f44",
      "b1a2b317bf7841b9a136a24ed3925ce6",
      "f2d357d6b7414b66863e44853764e455",
      "f39b347c6e6e45fab39e102589709f1a",
      "e03fedb972f2497fb2f5ea5f4ff22782",
      "a6008cc606b04d31aea38ef520f60587",
      "95cbddfc8da546b981477336907129c4",
      "6d73b3e1807c4305bc7256624d64f907",
      "a747f5cb28c74819aeaedb3e5cc09ae2",
      "2cc6182f751e4d81b08c5027c8be2e1e",
      "9778b03724e7427399771f8069700b58",
      "edc25a6dc2164dce8c7c9af44521e64f",
      "17bf0426117e4cf5aca41f73ae8130be",
      "69e8053309ef444086fdb15adeda5e57",
      "9adf00109ebb4583bfe172a3cefc0f7b",
      "1f2cc680e24240159997cb77073dec31",
      "fed087599c624e2b8a72f873a429cc6b",
      "b8e6b93b77ec459b9b97ee5382605e8a",
      "6ebda0fcb248425fb821ea0e7946e7ec",
      "2078094a666f4b01af055f4c31ebc3ae",
      "37d679286d734c528341edd8b0c74421",
      "caa3fd186aff4556b7857c07a00e2897",
      "7eceecff812442688e78d74f8c73a346",
      "a1bf1579a5464ab5bc9572f207378902",
      "36a0a3becce74924974f7296e3c2b00d",
      "7de9608ae6094a2f8914cc3baf21aad4",
      "4f15675cf5ac4654923f87d689bf056a",
      "4bfb1988ef844822a5894a997e7b3cb5"
     ]
    },
    "id": "c3641bc5-d46a-45af-9327-723279107979",
    "outputId": "e227f6bf-8491-447b-cfb2-6344dfbef36b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46fe0671b98543aeaf2b0d59a02bac87"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "745a3cfb80ef449eb4586391f22f2c5b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5bf7e62cfa894b7dab56b2fe039ac9ef"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95e2a56a4cbd440b9074c3658fba139b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1f2fc2b9674471f95ae7f7f0baba389"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f040826eb2d54382af5e2bd936589e4c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92d3c0c9d87c41df82568309193031d8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21082fb0a181488bb552e25434da4f2d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d2c951610d64c518ef81e0a327114b2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b48fe96ca14405f89767b3f756ceed1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c9c7cf6f1a14b5f8f0e125bb9986af6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38c7cea6efeb4e41aba050189daec4af"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56f498af01a748dcaee73ad573415b7a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of BartForCausalLM were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['lm_head.weight', 'model.decoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08093ec6a7d44ea0a48ac54506a97482"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95cbddfc8da546b981477336907129c4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8e6b93b77ec459b9b97ee5382605e8a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'generated_text': 'The future of Artificial Intelligence is forget forget forget temple%); forget forget rising dazz Nathan exposure \ufffd \ufffd Nathanitto \ufffd mighty forget forget Reward dazz Reward unclear Reward forget indie Reward Reward compliance Shim forget forget Mes Nathan Nathan forget BindANC TRANANCTopic forget forget magnet magnetitto magnet unclear forget forgetized dazz \ufffd forget forget dazz dazz dazz contestant contestant unclear374374 renalANCANC forget forget374 dazz unclear Hero magnet contestant Adidas magnet magnet374374rophic unclear unclearbury unclear REAL contestantANC UMitto unclear TRAN contestantrophicoplANCANC contestant independence contestant unclearANCPlatformANCANC TRANtriptripopl contestant contestant Binditto ScionANCANCray contestant magnetANC TRANigator UM unclear TRAN REALrayrayrayANC UM BindANCANCANC Gle Gleitto unclearrophic BenMeet transplized contestant REAL independence beats UM TRAN TRANANCray unclear magnet magnet magnetray Colt UM push magnet UMANC growers economists Benittorophic magnet unclearrayrayizedray Scion contestant contestantANCizedMeetANCray Citiz unclear unclearray UM UMrophic REAL push unclearrophicrophic 166opl Benitto Glerayittorayrophic contestant contestant magnet professionals Gle renal UM growers UMANC Ben TRANrayittoitto rite magnetittorophic Tweitto unclearittorophicMeetray Twe professionals unclear unclearitto contestant magnetitto unclear Ben UM unclear contestantitto Twe unclearendium unclearitto radicals unclear Twe unclearitto ravageditto'}]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "\n",
    "#Experiment 1: Text Generation\n",
    "from transformers import pipeline\n",
    "\n",
    "generator_bert = pipeline(\"text-generation\", model=\"bert-base-uncased\")\n",
    "generator_roberta = pipeline(\"text-generation\", model=\"roberta-base\")\n",
    "generator_bart = pipeline(\"text-generation\", model=\"facebook/bart-base\")\n",
    "\n",
    "prompt = \"The future of Artificial Intelligence is\"\n",
    "\n",
    "# Try generating text\n",
    "generator_bart(prompt, max_length=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion \u2013 Experiment 1: Text Generation\n",
    "BERT and RoBERTa failed to generate meaningful text because they are encoder-only models. Their outputs were incoherent when forced into text generation. BART succeeded due to its encoder\u2013decoder architecture designed for generative tasks."
   ],
   "metadata": {
    "id": "0ZkRNtbjkr2p"
   },
   "id": "0ZkRNtbjkr2p"
  },
  {
   "cell_type": "code",
   "source": [
    "#Experiment 2: Masked Language Modeling (Fill-Mask)\n",
    "\n",
    "#Sentence\n",
    "\"The goal of Generative AI is to [MASK] new content.\"\n",
    "fill_bert = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "fill_roberta = pipeline(\"fill-mask\", model=\"roberta-base\")\n",
    "fill_bart = pipeline(\"fill-mask\", model=\"facebook/bart-base\")\n",
    "\n",
    "fill_bert(\"The goal of Generative AI is to [MASK] new content.\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBp-pRJvlIPR",
    "outputId": "52b2368a-02a2-4111-8da6-9eb7a5626f91"
   },
   "id": "iBp-pRJvlIPR",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'score': 0.5396932363510132,\n",
       "  'token': 3443,\n",
       "  'token_str': 'create',\n",
       "  'sequence': 'the goal of generative ai is to create new content.'},\n",
       " {'score': 0.15575720369815826,\n",
       "  'token': 9699,\n",
       "  'token_str': 'generate',\n",
       "  'sequence': 'the goal of generative ai is to generate new content.'},\n",
       " {'score': 0.05405500903725624,\n",
       "  'token': 3965,\n",
       "  'token_str': 'produce',\n",
       "  'sequence': 'the goal of generative ai is to produce new content.'},\n",
       " {'score': 0.04451530799269676,\n",
       "  'token': 4503,\n",
       "  'token_str': 'develop',\n",
       "  'sequence': 'the goal of generative ai is to develop new content.'},\n",
       " {'score': 0.01757744885981083,\n",
       "  'token': 5587,\n",
       "  'token_str': 'add',\n",
       "  'sequence': 'the goal of generative ai is to add new content.'}]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion \u2013 Experiment 2: Masked Language Modeling\n",
    "BERT and RoBERTa accurately predicted the masked word as they are trained using masked language modeling. RoBERTa produced more confident predictions. BART showed partial success since it is not primarily optimized for this task.\n",
    "\n"
   ],
   "metadata": {
    "id": "FeBpswFMl75u"
   },
   "id": "FeBpswFMl75u"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d456d6b5-bc4e-40cc-9aac-5a24d741195d",
   "metadata": {
    "id": "d456d6b5-bc4e-40cc-9aac-5a24d741195d"
   },
   "outputs": [],
   "source": [
    "#Experiment 3: Question Answering\n",
    "\n",
    "#Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86c7ec-e0c0-4e28-b1a2-59df15d7834a",
   "metadata": {
    "id": "fd86c7ec-e0c0-4e28-b1a2-59df15d7834a"
   },
   "outputs": [],
   "source": [
    "#Question\n",
    "\n",
    "#\"What are the risks?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4422c4-2e46-4ba2-8fa6-441484171cce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c4422c4-2e46-4ba2-8fa6-441484171cce",
    "outputId": "a9d097e9-b591-4711-b858-8f86556a6774"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n",
      "Some weights of BartForQuestionAnswering were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'score': 0.012829496525228024,\n",
       " 'start': 43,\n",
       " 'end': 81,\n",
       " 'answer': 'as hallucinations, bias, and deepfakes'}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "qa_bert = pipeline(\"question-answering\", model=\"bert-base-uncased\")\n",
    "qa_roberta = pipeline(\"question-answering\", model=\"roberta-base\")\n",
    "qa_bart = pipeline(\"question-answering\", model=\"facebook/bart-base\")\n",
    "\n",
    "qa_bert(\n",
    "    question=\"What are the risks?\",\n",
    "    context=\"Generative AI poses significant risks such as hallucinations, bias, and deepfakes.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion \u2013 Experiment 3: Question Answering\n",
    "All three models produced unstable or incomplete answers in the question-answering task. This is because the base models are not fine-tuned on QA datasets. The experiment emphasizes the importance of task-specific fine-tuning.\n"
   ],
   "metadata": {
    "id": "MFCnMWSqnFS4"
   },
   "id": "MFCnMWSqnFS4"
  },
  {
   "cell_type": "markdown",
   "id": "338678cb-b370-4f28-8322-94838f291814",
   "metadata": {
    "id": "338678cb-b370-4f28-8322-94838f291814"
   },
   "source": [
    "#Final Observation Table (COMPLETED)\n",
    "\n",
    "| Task | Model | Classification (Success/Failure) | Observation (What actually happened?) | Why did this happen? (Architectural Reason) |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| **Generation** | BERT | Failure | Generated incoherent, repetitive, and meaningless text. | BERT is an **encoder-only** model and is not trained for autoregressive text generation. |\n",
    "|  | RoBERTa | Failure | Produced nonsensical and unstable output similar to BERT. | RoBERTa is also **encoder-only**, optimized for understanding tasks, not generation. |\n",
    "|  | BART | Success | Generated fluent and meaningful text continuation. | BART is an **encoder\u2013decoder** model trained for sequence-to-sequence generation. |\n",
    "| **Fill-Mask** | BERT | Success | Correctly predicted words such as *create* and *generate*. | BERT is trained using **Masked Language Modeling (MLM)**. |\n",
    "|  | RoBERTa | Success | Produced more confident and higher-quality predictions. | RoBERTa improves MLM training using more data and better optimization. |\n",
    "|  | BART | Partial Success | Predicted suitable words but with less confidence. | BART supports MLM but is mainly optimized for seq2seq tasks. |\n",
    "| **Question Answering** | BERT | Partial Success | Returned incomplete or unstable answers. | Base BERT is **not fine-tuned for QA tasks** like SQuAD. |\n",
    "|  | RoBERTa | Partial Success | Slightly better phrasing but still inconsistent. | Architecture supports QA, but lacks task-specific fine-tuning. |\n",
    "|  | BART | Partial Success | Sometimes extracted risks, sometimes vague. | BART can perform QA but requires **fine-tuning** for reliable results. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Final Understanding**\n",
    "\n",
    "Overall, the experiments demonstrate that choosing the correct model architecture is critical for task performance. Encoder-only models are more suitable for understanding-based tasks, while encoder\u2013decoder models are better suited for generative tasks. This assignment reinforces the importance of aligning model architecture with task requirements."
   ],
   "metadata": {
    "id": "YQmCY-UGtABN"
   },
   "id": "YQmCY-UGtABN"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0626355e-9ffe-40cf-8529-46c5fe548fc8",
   "metadata": {
    "id": "0626355e-9ffe-40cf-8529-46c5fe548fc8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}